'''
    Multi-target approach
    - DistComp prediction is single-target;
    - QueryTime, IndexTime, and Recall (in this order) are predicted
    using the previous meta-target predictions as meta-features
    -----------------
    1st: prediction of DC
    2nd: using [DC] as MF to predict QT
    3td: using [DC, QT] as MF to predict IT
    4th: using [DC, QT, IT] as MF to predict Recall
'''

import numpy as np
import pandas as pd
from itertools import product
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeRegressor

def read_data(data_path):
    df = pd.read_csv(data_path)
    df = df.sample(frac=1).copy()
    df.set_index('base', inplace=True)
    df.drop('uscities', inplace=True)

    statistical = [
        'attr_ent.mean',
        'iq_range.mean', 'iq_range.sd', 'kurtosis.mean', 'kurtosis.sd',
        'mad.mean', 'mad.sd', 'max.mean', 'max.sd', 'mean.mean', 'mean.sd',
        'median.mean', 'median.sd', 'min.mean', 'min.sd', 'nr_norm',
        'nr_outliers', 'range.mean', 'range.sd', 'sd.mean', 'sd.sd',
        'skewness.sd', 't_mean.mean', 't_mean.sd', 'var.mean', 'var.sd'
    ]
    others = [
        'QueryTime', 'DistComp', 'IndexTime',
        'nr_inst', 'IndexParams', 'inst_to_attr', 'id',
        'QueryTimeParams', 'k_searching', 'nr_attr'
    ]
    # sc = StandardScaler()
    # sc.fit(df[statistical])
    # df.loc[:, statistical] = sc.transform(df[statistical])
    df.loc[:, others] = df[others].apply(np.log)
    return df

def fit_model(X_train, y_train, random_state=0, model=RandomForestRegressor):
    reg = model(random_state=random_state)
    reg.fit(X_train, y_train)
    return reg

def ensamble_predictions(models, X_test):
    predictions = np.array([m.predict(X_test) for m in models])
    return predictions.mean(axis=0)

def format_scores(base_target, metatarget, approach, y_test, y_pred):
    return pd.Series({
        "base": base_target,
        "target": metatarget,
        "approach": approach.__name__,
        "r2": r2_score(y_test, y_pred),
        "mae": mean_absolute_error(y_test, y_pred),
        "mse": mean_squared_error(y_test, y_pred),
    }).to_frame().T

def format_predictions(X_test, y_test, y_pred, metatarget, approach):
    return pd.DataFrame({
        "base": X_test.index,
        "true": y_test[metatarget].values,
        "pred": y_pred,
        "target": [metatarget] * len(y_test),
        "NN": X_test.IndexParams.values,
        "R": X_test.QueryTimeParams.values,
        "graph_type": X_test.graph_type.values,
        "nr_inst": X_test.nr_inst.values,
        "approach": [approach.__name__] * len(y_test),
        "k_searching": X_test.k_searching.values
    })

def gmm(data, base_target):
    """
        Generic meta-model (GMM).
        ----------------------------------------------
        All meta-instances of our meta-dataset regarding all datasets
        were used for meta-training, except for the meta-instances
        regarding the goal dataset, which was used for meta-testing.
        ----------------------------------------------
    """
    train = data[data.index != base_target]
    test = data[data.index == base_target]
    return train, test[test.nr_inst == test.nr_inst.max()]

def tmm_gs(data, base_target):
    """
        Tuned meta-model using grid search (TMM-GS).
        ----------------------------------------------
        All meta-instances of our meta-dataset regarding all datasets
        (except for the ones referring to the goal dataset) plus meta-
        instances generated by a grid search performed over the goal
        dataset were used for meta-training and the goal dataset was
        used for testing.
        ----------------------------------------------
        GS params:
        NN = [1, 25, 70, 150],
        R = [1, 10, 40, 120],
        k = 30
    """
    train = data[data.index != base_target]
    test = data[data.index == base_target]
    gs_instances = test[
        (test.IndexParams.isin([1,25,70, 150])) &
        (test.QueryTimeParams.isin([1,10,40,120])) &
        (test.nr_inst == test.nr_inst.max())
    ]
    train = pd.concat([train, gs_instances])
    return train, test[test.nr_inst == test.nr_inst.max()]

def tmm_s(data, base_target):
    """
    Tuned meta-model using subsets (TMM-S).
    ----------------------------------------------
    Meta-instances of our meta-dataset regarding all datasets
    (except for the ones regarding the goal dataset) plus meta-
    instances of subsets of the real datasets were used for meta-
    training, the remaining meta-instances were used for meta-testing.
    ----------------------------------------------
    """
    sizes = [69900, 25274, 67940, 999900] # sizes of complete datasets
    train = data[data.index != base_target]
    test = data[data.index == base_target]

    subset_instances = test[test.nr_inst != test.nr_inst.max()]
    train = pd.concat([train, subset_instances])
    return train, test[test.nr_inst == test.nr_inst.max()]

if __name__ == "__main__":
    ##### setup
    metabase = 'data/metabase/metabase_all_k_search.csv'
    RESULTS = pd.DataFrame()
    SCORES = pd.DataFrame()
    META_TARGETS = ['DistComp', 'QueryTime', 'IndexTime', 'Recall']
    APPROACHES = [gmm, tmm_gs, tmm_s]
    DATASET_TARGET = ['mnist', 'colorHisto', 'moments', 'sift', 'texture']
    prods = product(APPROACHES, DATASET_TARGET)
    get_xy = lambda x: (x.drop(META_TARGETS, axis=1).copy(), x[META_TARGETS].copy())
    #####

    # reading meta-database
    data = read_data(metabase)
    # data = data[~data.index.str.startswith('base')]
    for approach, base_target in prods:
        # moduling data according to approach
        train, test = approach(data, base_target)

        # train, test
        X_train, y_train = get_xy(train)
        X_test, y_test = get_xy(test)

        # inducing a meta-model for each meta-target
        for metatarget in META_TARGETS:
            print('Fitting {} for base {} via {}'.format(metatarget, base_target, approach.__name__))
            models = [
                fit_model(
                    X_train,
                    y_train[metatarget],
                    random_state=RS,
                    model=RandomForestRegressor
                )
                for RS in range(5)
            ]
    
            y_pred = ensamble_predictions(models, X_test)

            scores = format_scores(base_target, metatarget, approach, y_test[metatarget], y_pred)
            SCORES = pd.concat([SCORES, scores], ignore_index=True)
            SCORES.to_csv('results/csv/multi_target/scores.csv', index=False)

            res = format_predictions(X_test, y_test, y_pred, metatarget, approach)
            RESULTS = pd.concat([RESULTS, res])
            RESULTS.to_csv('results/csv/predictions_{}.csv'.format(metatarget), index=False)
            
            # Multi target approach: using previous meta-target as new meta-feature
            # for the next meta-targer prediction
            X_train[metatarget] = y_train[metatarget]
            X_test[metatarget] = y_pred
