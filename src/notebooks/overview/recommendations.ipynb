{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('bmh')\n",
    "os.chdir('/home/seidi/Repositories/mestrado_final/')\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "import utils\n",
    "# Reading data\n",
    "mb = utils.read_mb()\n",
    "mb = utils.read_int_mb()\n",
    "mf = utils.read_mf()\n",
    "# mb['Recall'] = mb['Recall'].round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adbis_scores_path = 'data/results/info_sys_interpolated/adbis/scores.csv'\n",
    "adbis_preds_path = 'data/results/info_sys_interpolated/adbis/predictions.csv'\n",
    "# # adbis_scores = pd.read_csv(adbis_scores_path)\n",
    "# # adbis_scores[(adbis_scores.approach == 'tmm_s') & (adbis_scores.target == 'Recall')]\n",
    "# # adbis_scores.drop_duplicates(['base', 'target', 'approach'], inplace=True)\n",
    "# # adbis_scores = adbis_scores[adbis_scores.approach == 'tmm_s']\n",
    "    \n",
    "adbis_preds = pd.read_csv(adbis_preds_path)\n",
    "adbis_preds = adbis_preds[adbis_preds.target != 'IndexTime']\n",
    "adbis_preds.drop_duplicates(['base', 'target', 'approach', 'NN', 'R', 'graph_type', 'nr_inst', 'k_searching'], inplace=True)\n",
    "\n",
    "adbis_preds = adbis_preds.rename(columns={'approach': 'method', 'true': 'y_true', 'pred': 'y_pred', 'NN': 'IndexParams', 'R': 'QueryTimeParams'})\n",
    "adbis_preds.method = adbis_preds.method.apply(lambda x: x.replace('_', ''))\n",
    "adbis_preds.nr_inst = adbis_preds.nr_inst.apply(np.exp)\n",
    "adbis_preds.base = adbis_preds.base.apply(lambda x: x.split('_')[0])\n",
    "adbis_preds.base = adbis_preds.base + '_' + adbis_preds.nr_inst.round().astype(str).apply(lambda x: x.split('.')[0])\n",
    "# adbis_preds.base = adbis_preds.base.astype(str) + '_' + adbis_preds.nr_inst.round().astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_path = 'data/results/info_sys_interpolated/clustering_tuned/scores.csv'\n",
    "preds_path = 'data/results/info_sys_interpolated/clustering_tuned/predictions.csv'\n",
    "scores = pd.read_csv(scores_path)\n",
    "scores = scores[scores.feature_selection_method == 'rf']\n",
    "preds = pd.read_csv(preds_path)\n",
    "preds = preds[preds.target != 'IndexTime']\n",
    "preds = preds[preds.feature_selection_method == 'rf']\n",
    "\n",
    "scores.method = scores.method.apply(lambda x: x + '+')\n",
    "preds.method = preds.method.apply(lambda x: x + '+')\n",
    "preds = pd.concat([preds, adbis_preds])\n",
    "preds.drop(['feature_selection_method', 'nr_inst'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "method\n",
      "gmm       0.039788\n",
      "gmm+      0.028483\n",
      "tmmgs     0.029490\n",
      "tmmgs+    0.019581\n",
      "tmms      0.024069\n",
      "tmms+     0.016634\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Melt: columns to rows; Pivot: rows to columns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error\n",
    "k_searching = 1\n",
    "recommends = preds[preds.k_searching == k_searching].pivot(index=['base', 'IndexParams', 'QueryTimeParams', 'graph_type', 'method', 'k_searching'], columns='target', values=['y_true', 'y_pred']).copy()\n",
    "recommends.columns = [ '_'.join(x) for x in recommends.columns ]\n",
    "recommends.reset_index(inplace=True)\n",
    "err = recommends.groupby(['method']).apply(lambda x: mean_absolute_error(x.y_true_Recall, \n",
    "x.y_pred_Recall))\n",
    "print(err)\n",
    "# print(recommends.head()[['base', 'y_pred_Recall', 'method']])\n",
    "err = err.to_dict()\n",
    "f = lambda x: x.y_pred_Recall - err[x.method]\n",
    "recommends['y_pred_Recall'] = recommends[['method', 'y_pred_Recall']].apply(f, axis=1)\n",
    "# print(recommends.head()[['base', 'y_pred_Recall', 'method']])\n",
    "\n",
    "recommends[['y_true_Recall', 'y_pred_Recall']] = recommends[['y_true_Recall', 'y_pred_Recall']].round(decimals=2)\n",
    "recommends = recommends.rename(columns={'method': 'approach'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.0\n",
      "120.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Pegar valor bom frequente, independente do dataset, afinal nós não estamos considerando nenhuma informação do dataset de entrada (um default da biblioteca):\n",
    "    - filtrar os que atendem o requisito de recall minimo, considerando todos os datasets, todos os grafos e todos os parametros\n",
    "    - identificar os top 10% por métrica de otimização\n",
    "    - identificar o grafo mais frequente\n",
    "    - parâmetros:\n",
    "        - a) são escolhidos através da média do NN e a média do R para esse NN (recomendação \"justa\", espera-se que não atinja o requisito em 50% dos casos). Por que NN primeiro? Porque o R é ajustável tendo o grafo construído, o NN requer reconstrução do grafo\n",
    "        - b) são escolhidos através do máximo NN e a média do R para esse NN (recomendação \"frouxa\" com mais chances de atingir o requisito)\n",
    "'''\n",
    "# Recall .90 otimizando QT \n",
    "atende_requisito = mb[(mb['Recall'] >= 0.99) & (mb['QueryTimeParams'] <= 120)].copy() # NN não está multiplicado pro NSW\n",
    "top10_qt = atende_requisito.sort_values(by='IndexParams').iloc[:int(len(atende_requisito)/10), :]\n",
    "# top10_nn = atende_requisito.sort_values(by='IndexParams').iloc[:int(len(atende_requisito)/10), :]\n",
    "moda_qt = top10_qt.graph_type.mode().values[0]\n",
    "top10_qt_moda_grafo = top10_qt[top10_qt.graph_type == moda_qt]\n",
    "\n",
    "# # NN Ajustado\n",
    "# top10_nn_qt = top10_qt_moda_grafo.IndexParams.mean()\n",
    "# nn_unique = top10_qt_moda_grafo.IndexParams.unique()\n",
    "# diff_nn = [abs(top10_nn_qt - nn) for nn in nn_unique]\n",
    "# top10_nn_qt = pd.DataFrame({\n",
    "#     'diff': diff_nn,\n",
    "#     'nn_unique': nn_unique\n",
    "# }).sort_values(by='diff').iloc[0, 1]\n",
    "# Frouxa\n",
    "top10_nn_qt = top10_qt_moda_grafo.IndexParams.max()\n",
    "\n",
    "# RR Ajustado\n",
    "# top10_rr_qt = top10_qt_moda_grafo[top10_qt_moda_grafo.IndexParams == top10_nn_qt].QueryTimeParams.mean()\n",
    "# rr_unique = top10_qt_moda_grafo.QueryTimeParams.unique()\n",
    "# diff_rr = [abs(top10_rr_qt - rr) for rr in rr_unique]\n",
    "# top10_rr_qt = pd.DataFrame({\n",
    "#     'diff': diff_rr,\n",
    "#     'nn_unique': rr_unique\n",
    "# }).sort_values(by='diff').iloc[0, 1]\n",
    "# # RR frouxo\n",
    "top10_rr_qt = top10_qt_moda_grafo[top10_qt_moda_grafo.IndexParams == top10_nn_qt].QueryTimeParams.max()\n",
    "\n",
    "print(top10_nn_qt)\n",
    "print(top10_rr_qt)\n",
    "print(moda_qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_BASES = [\n",
    "    'texture_67940', 'sift_999900', 'moments_67940',\n",
    "    'mnist121d_69900', 'fashion_69900',\n",
    "    'colorHisto_67940', 'mnist_69900', \n",
    "    'cophir282_999900', 'cophir64_999900',\n",
    "    'base71_999900',\n",
    "    \n",
    "    'mnist121d_16000', 'mnist121d_32000', \n",
    "    'mnist_16000', 'mnist_32000', \n",
    "    'cophir282_500000', 'cophir282_100000',\n",
    "    'cophir64_500000', 'cophir64_100000', \n",
    "    'base71_100000', 'base71_500000',\n",
    "    'texture_16000', 'texture_32000',\n",
    "    'sift_500000', 'sift_100000',\n",
    "    'moments_16000', 'moments_32000',\n",
    "    'fashion_16000', 'fashion_32000',\n",
    "    'colorHisto_16000', 'colorHisto_32000',\n",
    "]\n",
    "average_params = {\n",
    "    'IndexParams': {\n",
    "        'Heavy': {\n",
    "            0.90: {'nn': 20, 'rr': 60, 'gt': 0},\n",
    "            0.95: {'nn': 20, 'rr': 60, 'gt': 0},\n",
    "            0.99: {'nn': 25, 'rr': 60, 'gt': 0} \n",
    "        },\n",
    "        'Loose': {\n",
    "            0.90: {'nn': 30, 'rr': 120, 'gt': 0},\n",
    "            0.95: {'nn': 30, 'rr': 120, 'gt': 0},\n",
    "            0.99: {'nn': 35, 'rr': 120, 'gt': 0}\n",
    "        }\n",
    "    },\n",
    "    'QueryTime': {\n",
    "        'Heavy': {\n",
    "            0.90: {'nn': 70, 'rr': 6, 'gt': 1},\n",
    "            0.95: {'nn': 60, 'rr': 5, 'gt': 0},\n",
    "            0.99: {'nn': 70, 'rr': 7, 'gt': 0} \n",
    "        },\n",
    "        'Loose': {\n",
    "            0.90: {'nn': 100, 'rr': 10, 'gt': 1},\n",
    "            0.95: {'nn': 100, 'rr': 8, 'gt': 0},\n",
    "            0.99: {'nn': 100, 'rr': 10, 'gt': 0}\n",
    "        }\n",
    "    },\n",
    "    'DistComp': {\n",
    "        'Heavy': {\n",
    "            0.90: {'nn': 65, 'rr': 5, 'gt': 2},\n",
    "            0.95: {'nn': 60, 'rr': 4, 'gt': 0},\n",
    "            0.99: {'nn': 70, 'rr': 7, 'gt': 0} \n",
    "        },\n",
    "        'Loose': {\n",
    "            0.90: {'nn': 100, 'rr': 8, 'gt': 2},\n",
    "            0.95: {'nn': 100, 'rr': 5, 'gt': 0},\n",
    "            0.99: {'nn': 100, 'rr': 10, 'gt': 0}\n",
    "        }\n",
    "    },\n",
    "}\n",
    "def get_baseline(mb, optmizing_name, optmizing, approach, required_recall):\n",
    "    tmp = mb[\n",
    "        (mb.IndexParams == average_params[optmizing][approach][required_recall]['nn']) &\n",
    "        (mb.QueryTimeParams == average_params[optmizing][approach][required_recall]['rr']) & \n",
    "        (mb.graph_type == average_params[optmizing][approach][required_recall]['gt']) & \n",
    "        (mb.k_searching == k_searching) &\n",
    "        (mb.index.isin(REAL_BASES))\n",
    "        # (recommends.approach == 'gmm+')\n",
    "    ]\n",
    "    tmp.reset_index(inplace=True)\n",
    "    return pd.DataFrame(\n",
    "        data={\n",
    "            'base': tmp.base, \n",
    "            'IndexParams': tmp.IndexParams, \n",
    "            'QueryTimeParams': tmp.QueryTimeParams,\n",
    "            'graph_type': tmp.graph_type,\n",
    "            'approach': approach,\n",
    "            'k_searching': tmp.k_searching,\n",
    "            'y_true_DistComp': tmp.DistComp,\n",
    "            'y_true_QueryTime': tmp.QueryTime,\n",
    "            'y_true_Recall': tmp.Recall,\n",
    "            'y_pred_DistComp': tmp.DistComp, \n",
    "            'y_pred_QueryTime': tmp.QueryTime,\n",
    "            'y_pred_Recall': tmp.Recall,\n",
    "            'optmizing': optmizing_name[optmizing],\n",
    "            'required_recall': required_recall\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>NN</th>\n",
       "      <th>R</th>\n",
       "      <th>graph_type</th>\n",
       "      <th>approach</th>\n",
       "      <th>k_searching</th>\n",
       "      <th>Distance Computations</th>\n",
       "      <th>Query Time (ms)</th>\n",
       "      <th>Recall</th>\n",
       "      <th>y_pred_DistComp</th>\n",
       "      <th>y_pred_QueryTime</th>\n",
       "      <th>y_pred_Recall</th>\n",
       "      <th>optmizing</th>\n",
       "      <th>required_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>base71_100000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GridSearch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13448.852316</td>\n",
       "      <td>0.591513</td>\n",
       "      <td>0.90</td>\n",
       "      <td>9.556739</td>\n",
       "      <td>0.647259</td>\n",
       "      <td>0.86</td>\n",
       "      <td>qt</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10911</th>\n",
       "      <td>base71_500000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GridSearch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20696.700000</td>\n",
       "      <td>1.715990</td>\n",
       "      <td>0.90</td>\n",
       "      <td>9.882815</td>\n",
       "      <td>2.123658</td>\n",
       "      <td>0.88</td>\n",
       "      <td>qt</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14973</th>\n",
       "      <td>base71_999900</td>\n",
       "      <td>140.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GridSearch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21910.939801</td>\n",
       "      <td>3.728871</td>\n",
       "      <td>0.92</td>\n",
       "      <td>9.770167</td>\n",
       "      <td>2.193318</td>\n",
       "      <td>0.94</td>\n",
       "      <td>qt</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21369</th>\n",
       "      <td>colorHisto_16000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GridSearch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>441.558816</td>\n",
       "      <td>0.015332</td>\n",
       "      <td>0.94</td>\n",
       "      <td>6.020707</td>\n",
       "      <td>0.025917</td>\n",
       "      <td>0.93</td>\n",
       "      <td>qt</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28209</th>\n",
       "      <td>colorHisto_32000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GridSearch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>501.287890</td>\n",
       "      <td>0.023723</td>\n",
       "      <td>0.93</td>\n",
       "      <td>6.029161</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.93</td>\n",
       "      <td>qt</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dataset     NN     R  graph_type    approach  k_searching  \\\n",
       "3735      base71_100000   70.0  40.0         1.0  GridSearch          1.0   \n",
       "10911     base71_500000  100.0  40.0         1.0  GridSearch          1.0   \n",
       "14973     base71_999900  140.0  10.0         0.0  GridSearch          1.0   \n",
       "21369  colorHisto_16000   70.0   1.0         1.0  GridSearch          1.0   \n",
       "28209  colorHisto_32000   70.0   1.0         1.0  GridSearch          1.0   \n",
       "\n",
       "       Distance Computations  Query Time (ms)  Recall  y_pred_DistComp  \\\n",
       "3735            13448.852316         0.591513    0.90         9.556739   \n",
       "10911           20696.700000         1.715990    0.90         9.882815   \n",
       "14973           21910.939801         3.728871    0.92         9.770167   \n",
       "21369             441.558816         0.015332    0.94         6.020707   \n",
       "28209             501.287890         0.023723    0.93         6.029161   \n",
       "\n",
       "       y_pred_QueryTime  y_pred_Recall optmizing  required_recall  \n",
       "3735           0.647259           0.86        qt              0.9  \n",
       "10911          2.123658           0.88        qt              0.9  \n",
       "14973          2.193318           0.94        qt              0.9  \n",
       "21369          0.025917           0.93        qt              0.9  \n",
       "28209          0.028571           0.93        qt              0.9  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = [5., 25., 70., 100.]\n",
    "R = [1., 10., 40., 120.]\n",
    "pred_recall = 'y_pred_Recall'\n",
    "true_recall = 'y_true_Recall'\n",
    "\n",
    "def get_best(df, recall='y_true_Recall', optmizing='y_true_QueryTime', method_name='gs', optmizing_name='qt', required_recall=0.9):\n",
    "    ix = df[df[recall] >= required_recall].groupby(['base'])[optmizing].idxmin().values\n",
    "    tmp = df.loc[ix, :].copy()\n",
    "    tmp['approach'] = method_name\n",
    "    tmp['optmizing'] = optmizing_name\n",
    "    return tmp\n",
    "\n",
    "def get_rec(recommends, required_recall, optmizing='y_pred_QueryTime', optmizing_name='qt'):\n",
    "    cols = ['base', 'IndexParams', 'QueryTimeParams', 'graph_type', 'approach', 'y_pred_Recall', 'y_true_Recall']\n",
    "    ix = recommends[recommends['y_pred_Recall'] >= required_recall].groupby(['base', 'approach'])[optmizing].nsmallest(1).index.get_level_values(2).values\n",
    "    tmp = recommends.loc[ix, cols].groupby(['base', 'approach'])[['graph_type', 'QueryTimeParams', 'IndexParams']].median().reset_index()\n",
    "    index = ['base','approach','graph_type','QueryTimeParams','IndexParams']\n",
    "    tmp = recommends.join(tmp.set_index(index), on=index, how='inner', lsuffix='l_')\n",
    "    tmp['optmizing'] = optmizing_name\n",
    "    return tmp\n",
    "\n",
    "cols = np.append(recommends.columns, np.array(['optmizing', 'required_recall']))\n",
    "final_recommendations = pd.DataFrame(columns=cols)\n",
    "optmizing = 'IndexParams'\n",
    "optmizing_name = {\n",
    "    'QueryTime': 'qt',\n",
    "    'IndexParams': 'nn',\n",
    "    'DistComp': 'dt'\n",
    "}\n",
    "\n",
    "flag = False\n",
    "for optmizing in ['QueryTime', 'IndexParams', 'DistComp']:\n",
    "    for required_recall in [0.90, 0.95, 0.99]:\n",
    "        # GS\n",
    "        gs = recommends.copy()\n",
    "        gs = gs[(gs.IndexParams.isin(NN)) & (gs.QueryTimeParams.isin(R))]\n",
    "        tmp = get_best(gs, recall=true_recall, optmizing='y_true_' + optmizing, method_name='GridSearch', optmizing_name=optmizing_name[optmizing], required_recall=required_recall) if optmizing != 'IndexParams' else get_best(gs, recall=true_recall, optmizing=optmizing, method_name='GridSearch', optmizing_name=optmizing_name[optmizing], required_recall=required_recall)\n",
    "        tmp['required_recall'] = required_recall\n",
    "        tmp['approach'] = 'GridSearch'\n",
    "        final_recommendations = pd.concat([final_recommendations.loc[:, cols], tmp.loc[:, cols]])\n",
    "        \n",
    "        # OPTIMAL \n",
    "        tmp = get_best(recommends.copy(), recall=true_recall, optmizing='y_true_' + optmizing, method_name='Optimal', optmizing_name=optmizing_name[optmizing], required_recall=required_recall) if optmizing != 'IndexParams' else get_best(recommends, recall=true_recall, optmizing=optmizing, method_name='Optimal', optmizing_name=optmizing_name[optmizing], required_recall=required_recall)\n",
    "        tmp['required_recall'] = required_recall \n",
    "        tmp['approach'] = 'Optimal'\n",
    "        final_recommendations = pd.concat([final_recommendations.loc[:, cols], tmp.loc[:, cols]])\n",
    "        \n",
    "        # AVERAGE PARAMS\n",
    "        # tmp = mb[\n",
    "        #     (mb.IndexParams == average_params[optmizing]['justo'][required_recall]['nn']) &\n",
    "        #     (mb.QueryTimeParams == average_params[optmizing]['justo'][required_recall]['rr']) &\n",
    "        #     (mb.graph_type == average_params[optmizing]['justo'][required_recall]['gt']) &\n",
    "        #     (mb.k_searching == k_searching)\n",
    "        # ].copy()\n",
    "\n",
    "        # tmp['approach'] = 'Heavy'\n",
    "        # tmp['optmizing'] = optmizing_name[optmizing]\n",
    "        # tmp['required_recall'] = required_recall\n",
    "        # final_recommendations = pd.concat([final_recommendations, tmp])\n",
    "        tmp = get_baseline(mb, optmizing_name, optmizing, 'Heavy', required_recall)\n",
    "        final_recommendations = pd.concat([final_recommendations, tmp])\n",
    "                \n",
    "        # AVERAGE PARAMS\n",
    "        # tmp = recommends[\n",
    "        #     (recommends.IndexParams == average_params[optmizing]['frouxo'][required_recall]['nn']) &\n",
    "        #     (recommends.QueryTimeParams == average_params[optmizing]['frouxo'][required_recall]['rr']) &\n",
    "        #     (recommends.graph_type == average_params[optmizing]['frouxo'][required_recall]['gt']) &\n",
    "        #     (recommends.approach == 'gmm+')\n",
    "        # ].copy()\n",
    "\n",
    "        # tmp['approach'] = 'Light'\n",
    "        # tmp['optmizing'] = optmizing_name[optmizing]\n",
    "        # tmp['required_recall'] = required_recall\n",
    "        tmp = get_baseline(mb, optmizing_name, optmizing, 'Loose', required_recall)\n",
    "        tmp['approach'] = 'Light'\n",
    "        final_recommendations = pd.concat([final_recommendations, tmp])\n",
    "                \n",
    "        # RECOMMENDED\n",
    "        if required_recall == 0.99:\n",
    "            # required_recall -= error\n",
    "            f = lambda x: x.y_pred_Recall + err[x.approach]\n",
    "            recommends['y_pred_Recall'] = recommends[['approach', 'y_pred_Recall']].apply(f, axis=1)\n",
    "            flag = True\n",
    "        tmp = get_rec(recommends.copy(), required_recall, optmizing='y_pred_' + optmizing, optmizing_name=optmizing_name[optmizing]) if optmizing != 'IndexParams' else get_rec(recommends, required_recall, optmizing=optmizing, optmizing_name=optmizing_name[optmizing])\n",
    "\n",
    "        if flag:\n",
    "            flag = False\n",
    "            f = lambda x: x.y_pred_Recall - err[x.approach]\n",
    "            recommends['y_pred_Recall'] = recommends[['approach', 'y_pred_Recall']].apply(f, axis=1)\n",
    "        tmp['required_recall'] = required_recall\n",
    "        final_recommendations = pd.concat([final_recommendations, tmp])\n",
    "\n",
    "final_recommendations.loc[:, ['y_true_QueryTime', 'y_true_DistComp', 'y_pred_QueryTime']] = final_recommendations.loc[:, ['y_true_QueryTime', 'y_true_DistComp', 'y_pred_QueryTime']].apply(np.exp)\n",
    "# final_recommendations.base = final_recommendations.base.apply(lambda x: x.split('_')[0])\n",
    "final_recommendations = final_recommendations.rename(columns={\n",
    "    'y_true_QueryTime': 'Query Time (ms)',\n",
    "    'y_true_Recall': 'Recall',\n",
    "    'IndexParams': 'NN',\n",
    "    'QueryTimeParams': 'R',\n",
    "    'y_true_DistComp': 'Distance Computations',\n",
    "    'method': 'Method',\n",
    "    'base': 'Dataset'\n",
    "})\n",
    "final_recommendations.NN = np.where(\n",
    "    final_recommendations.graph_type == 0, final_recommendations.NN * 2, final_recommendations.NN\n",
    ")\n",
    "# final_recommendations.sort_values(by='Dataset', inplace=True)\n",
    "# base_order = ['texture', 'moments', 'colorHisto', 'mnist', 'mnist121d', 'fashion', 'sift', 'cophir282', 'cophir64', 'base71'] \n",
    "# base_order = ['texture_67940', 'moments_67940', 'colorHisto_67940', 'mnist_69900', 'mnist121d_69900', 'fashion_69900', 'sift_999900', 'cophir282_999900', 'cophir64_999900', 'base71_999900',]\n",
    "# if k_searching==10:\n",
    "#     base_order.remove('base71')\n",
    "# final_recommendations = final_recommendations[final_recommendations.Dataset.isin(base_order)]\n",
    "# final_recommendations = final_recommendations.set_index('Dataset').loc[base_order, :].reset_index()\n",
    "# final_recommendations = final_recommendations[final_recommendations.approach != 'tmmgs+']\n",
    "final_recommendations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_recommendations = final_recommendations[final_recommendations.Dataset.isin(REAL_BASES)]\n",
    "final_recommendations.to_csv(f'src/notebooks/overview/recommendations/final_recs_k={k_searching}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "approach\n",
       "GridSearch    1.000000\n",
       "gmm+          0.888889\n",
       "tmmgs+        0.881481\n",
       "Light         0.870370\n",
       "tmmgs         0.859259\n",
       "gmm           0.837037\n",
       "tmms+         0.829630\n",
       "Heavy         0.711111\n",
       "tmms          0.644444\n",
       "Name: Yes, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melt: columns to rows; Pivot: rows to columns\n",
    "\n",
    "final_recommendations['Acertou'] = np.where(\n",
    "    final_recommendations.Recall >= final_recommendations.required_recall, True, False\n",
    ")\n",
    "\n",
    "x=final_recommendations[~final_recommendations.isin(['Optimal'])].groupby('approach').Acertou.value_counts()\n",
    "soma = final_recommendations[~final_recommendations.isin(['Optimal'])].approach.value_counts()\n",
    "x.name = 'k'\n",
    "x = x.reset_index(level=1)\n",
    "a = (x.k/soma).to_frame()\n",
    "a['Acertou'] = x.Acertou\n",
    "a.reset_index(inplace=True)\n",
    "a = a.rename(columns={0: 'rate', 'index': 'approach'})\n",
    "a = a.append(pd.Series(['GridSearch', False, 0], index=['approach', 'Acertou', 'rate']).T, ignore_index=True)\n",
    "a.Acertou = np.where(a.Acertou == True, 'Yes', 'No')\n",
    "a = a.rename(columns={'Acertou': 'Satisfied'})\n",
    "a.pivot(index='Satisfied', columns='approach', values='rate').loc[:, ['GridSearch', 'Light', 'Heavy', 'gmm', 'tmmgs', 'tmms', 'gmm+', 'tmmgs+', 'tmms+']].T['Yes'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1,2, dpi=100, figsize=(18,4))\n",
    "# axes = iter(axes.reshape(-1))\n",
    "# for b in ['base71_100000', 'colorHisto_16000']:\n",
    "#     ax = next(axes)\n",
    "#     tmp = recommends[(recommends.base.str.startswith(b)) & (recommends.approach == 'gmm')].copy()\n",
    "#     tmp['RecInt'] = pd.cut(recommends.y_true_Recall, bins=10)\n",
    "#     tmp = pd.melt(tmp, id_vars='RecInt', value_vars=['y_true_Recall', 'y_pred_Recall'])\n",
    "#     sns.boxplot(x='RecInt', y='value', hue='variable', data=tmp, ax=ax)\n",
    "#     ax.set_title(b)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
